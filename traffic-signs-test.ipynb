{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "\n",
    "# TODO: fill this in based on where you saved the training and testing data\n",
    "training_file = 'train.p'\n",
    "testing_file = 'test.p'\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 39209\n",
      "Number of testing examples = 12630\n",
      "Image data shape = (32, 32, 3)\n",
      "Number of classes = 43\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "### To start off let's do a basic data summary.\n",
    "\n",
    "# TODO: number of training examples\n",
    "n_train = X_train.shape[0]\n",
    "\n",
    "# TODO: number of testing examples\n",
    "n_test = X_test.shape[0]\n",
    "\n",
    "# TODO: what's the shape of an image?\n",
    "image_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3])\n",
    "\n",
    "# TODO: how many classes are in the dataset\n",
    "n_classes = np.unique(y_train).shape[0]\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tunguz/.local/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.cross_validation import KFold\n",
    "import tensorflow as tf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Generate data additional (if you want to!)\n",
    "### and split the data into training/validation/testing sets here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "X_train_scaled = (X_train - np.mean(X_train))/(256-np.mean(X_train))\n",
    "X_test_scaled = (X_test- np.mean(X_train))/(256-np.mean(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0029803106171309626"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features='all', dtype=<class 'numpy.float64'>,\n",
       "       handle_unknown='error', n_values='auto', sparse=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.fit(y_train.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = ohe.transform(y_train.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = ohe.transform(y_test.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_train, n_folds=306, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.003\n",
    "batch_size = 128\n",
    "training_epochs = 30\n",
    "\n",
    "n_input = 32*32*3  # MNIST data input (Shape: 28*28)\n",
    "n_classes = 43  # MNIST total classes (0-9 digits)\n",
    "\n",
    "layer_width = {\n",
    "    'layer_1': 64,\n",
    "    'layer_2': 128,\n",
    "    'layer_3': 256,\n",
    "    'fully_connected_1': 1024,\n",
    "    'fully_connected_2': 512\n",
    "}\n",
    "\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(\n",
    "        x,\n",
    "        ksize=[1, k, k, 1],\n",
    "        strides=[1, k, k, 1],\n",
    "        padding='SAME')\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'layer_1': tf.Variable(tf.truncated_normal(\n",
    "        [5, 5, 3, layer_width['layer_1']],stddev = 0.05)),\n",
    "    'layer_2': tf.Variable(tf.truncated_normal(\n",
    "        [5, 5, layer_width['layer_1'], layer_width['layer_2']], stddev = 0.05)),\n",
    "    'layer_3': tf.Variable(tf.truncated_normal(\n",
    "        [5, 5, layer_width['layer_2'], layer_width['layer_3']], stddev = 0.05)),\n",
    "    'fully_connected_1': tf.Variable(tf.truncated_normal(\n",
    "        [2048, layer_width['fully_connected_1']], stddev = 0.05)),\n",
    "    'fully_connected_2': tf.Variable(tf.truncated_normal(\n",
    "        [layer_width['fully_connected_1'], layer_width['fully_connected_2']], stddev = 0.05)),\n",
    "    'out': tf.Variable(tf.truncated_normal(\n",
    "        [layer_width['fully_connected_2'], n_classes], stddev = 0.05))\n",
    "}\n",
    "biases = {\n",
    "    'layer_1': tf.Variable(tf.zeros(layer_width['layer_1'])),\n",
    "    'layer_2': tf.Variable(tf.zeros(layer_width['layer_2'])),\n",
    "    'layer_3': tf.Variable(tf.zeros(layer_width['layer_3'])),\n",
    "    'fully_connected_1': tf.Variable(tf.zeros(layer_width['fully_connected_1'])),\n",
    "    'fully_connected_2': tf.Variable(tf.zeros(layer_width['fully_connected_2'])),\n",
    "    'out': tf.Variable(tf.zeros(n_classes))\n",
    "}\n",
    "\n",
    "# Create model\n",
    "def conv_net(x, weights, biases):\n",
    "    # Layer 1\n",
    "    conv1 = conv2d(x, weights['layer_1'], biases['layer_1'])\n",
    "    conv1 = maxpool2d(conv1)\n",
    "\n",
    "    # Layer 2\n",
    "    conv2 = conv2d(conv1, weights['layer_2'], biases['layer_2'])\n",
    "    conv2 = maxpool2d(conv2)\n",
    "\n",
    "    # Layer 3\n",
    "    conv3 = conv2d(conv2, weights['layer_3'], biases['layer_3'])\n",
    "    conv3 = maxpool2d(conv2)\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv3 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(\n",
    "        conv3,\n",
    "        [-1, weights['fully_connected_1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(\n",
    "        tf.matmul(fc1, weights['fully_connected_1']),\n",
    "        biases['fully_connected_1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    fc2 = tf.add(\n",
    "        tf.matmul(fc1, weights['fully_connected_2']),\n",
    "        biases['fully_connected_2'])\n",
    "    fc2 = tf.nn.relu(fc2)\n",
    "\n",
    "    # Output Layer - class prediction\n",
    "    out = tf.add(tf.matmul(fc2, weights['out']), biases['out'])\n",
    "    return out\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, 32, 32, 3])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "logits = conv_net(x, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-28-c7896526a66c>:10 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\\\n",
    "    .minimize(cost)\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 3.298856735 accuracy= 0.148437500\n",
      "Epoch: 0002 cost= 3.069041729 accuracy= 0.218750000\n",
      "Epoch: 0003 cost= 2.766264677 accuracy= 0.296875000\n",
      "Epoch: 0004 cost= 2.397610903 accuracy= 0.375000000\n",
      "Epoch: 0005 cost= 2.029237747 accuracy= 0.460937500\n",
      "Epoch: 0006 cost= 1.707121253 accuracy= 0.593750000\n",
      "Epoch: 0007 cost= 1.423470020 accuracy= 0.664062500\n",
      "Epoch: 0008 cost= 1.189630985 accuracy= 0.734375000\n",
      "Epoch: 0009 cost= 1.002859235 accuracy= 0.757812500\n",
      "Epoch: 0010 cost= 0.852782786 accuracy= 0.789062500\n",
      "Epoch: 0011 cost= 0.735143185 accuracy= 0.812500000\n",
      "Epoch: 0012 cost= 0.641408861 accuracy= 0.843750000\n",
      "Epoch: 0013 cost= 0.562160790 accuracy= 0.859375000\n",
      "Epoch: 0014 cost= 0.494858384 accuracy= 0.890625000\n",
      "Epoch: 0015 cost= 0.438961297 accuracy= 0.914062500\n",
      "Epoch: 0016 cost= 0.391159326 accuracy= 0.921875000\n",
      "Epoch: 0017 cost= 0.351194859 accuracy= 0.937500000\n",
      "Epoch: 0018 cost= 0.317304254 accuracy= 0.937500000\n",
      "Epoch: 0019 cost= 0.286753058 accuracy= 0.945312500\n",
      "Epoch: 0020 cost= 0.260963976 accuracy= 0.953125000\n",
      "Epoch: 0021 cost= 0.237711579 accuracy= 0.960937500\n",
      "Epoch: 0022 cost= 0.217285022 accuracy= 0.960937500\n",
      "Epoch: 0023 cost= 0.199854344 accuracy= 0.953125000\n",
      "Epoch: 0024 cost= 0.183957279 accuracy= 0.968750000\n",
      "Epoch: 0025 cost= 0.169440225 accuracy= 0.976562500\n",
      "Epoch: 0026 cost= 0.157090738 accuracy= 0.976562500\n",
      "Epoch: 0027 cost= 0.145755857 accuracy= 0.976562500\n",
      "Epoch: 0028 cost= 0.136005670 accuracy= 0.976562500\n",
      "Epoch: 0029 cost= 0.127421945 accuracy= 0.976562500\n",
      "Epoch: 0030 cost= 0.118936017 accuracy= 0.976562500\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        for (i, j) in kf:\n",
    "            batch_x, batch_y = X_train_scaled[j], y_train[j]\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "        # Display logs per epoch step\n",
    "        c = sess.run(cost, feed_dict={x: batch_x, y: batch_y})\n",
    "        a = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y})\n",
    "        print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(c), \"accuracy=\", \"{:.9f}\".format(a))\n",
    "    print(\"Optimization Finished!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0266825\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(\n",
    "            \"Accuracy:\",\n",
    "            accuracy.eval({x: X_test_scaled, y: y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
